{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c6b014-e677-4619-8ab3-e59f6ca1a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aabe6a6-0ce7-4424-9ac7-94340584b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import segmentation_models_pytorch_3d as smp\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52239e7b-3bf0-486b-931e-bace21a3d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "log_filename = f'defected-ribcage-encoder_{time.strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename=log_filename, encoding='utf-8', level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger.info(\"Started Importing Necessary Libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89efa277-4d48-4b01-8125-85fb3299fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ribfrac_number(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    match = re.search(r'RibFrac(\\d+)', base)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def find_matching_files(data_files, label_files):\n",
    "    data_dict = {extract_ribfrac_number(f): f for f in data_files}\n",
    "    label_dict = {extract_ribfrac_number(f): f for f in label_files}\n",
    "    \n",
    "    matched_pairs = []\n",
    "    for num in data_dict.keys():\n",
    "        if num in label_dict:\n",
    "            matched_pairs.append((data_dict[num], label_dict[num]))\n",
    "        elif num - 1 in label_dict:  # Check for off-by-one match\n",
    "            matched_pairs.append((data_dict[num], label_dict[num - 1]))\n",
    "    \n",
    "    return matched_pairs\n",
    "\n",
    "def is_valid_pair(data_file, label_file):\n",
    "    #logger.debug(f\"Checking pair: {os.path.basename(data_file)} - {os.path.basename(label_file)}\")\n",
    "    \n",
    "    try:\n",
    "        label = nib.load(label_file).get_fdata()\n",
    "        if np.all(label == 0) or np.isnan(label).any() or np.isinf(label).any():\n",
    "            #logger.debug(f\"Label file contains invalid data (all zeros, NaNs, or Infs): {label_file}\")\n",
    "            return False\n",
    "        #logger.debug(f\"Valid pair: {os.path.basename(data_file)} - {os.path.basename(label_file)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        #logger.error(f\"Error loading {label_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_for_invalid_values(tensor, tensor_name=\"tensor\"):\n",
    "    if torch.isnan(tensor).any():\n",
    "        logger.error(f\"NaN detected in {tensor_name}\")\n",
    "    if torch.isinf(tensor).any():\n",
    "        logger.error(f\"Inf detected in {tensor_name}\")\n",
    "\n",
    "def compute_mean_std(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=10, num_workers=0, shuffle=False)\n",
    "    \n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        data = batch['data']\n",
    "        batch_samples = data.size(0)  # Get the batch size\n",
    "        data = data.view(batch_samples, data.size(1), -1)  # Flatten the data\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1813d1-6d29-413f-9751-d6897190d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class with Dynamic Filtering\n",
    "class MedicalDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_list, label_list, mean, std, transform=None):\n",
    "        logger.info(f\"Initializing dataset with {len(data_list)} data files and {len(label_list)} label files\")\n",
    "        \n",
    "        self.matched_pairs = find_matching_files(data_list, label_list)\n",
    "        self.valid_pairs = [pair for pair in self.matched_pairs if is_valid_pair(*pair)]\n",
    "        \n",
    "        #logger.info(f\"Total pairs: {len(self.matched_pairs)}, Valid pairs: {len(self.valid_pairs)}\")\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        # Log all valid pairs\n",
    "        #for data, label in self.valid_pairs:\n",
    "         #   logger.debug(f\"Valid pair: {os.path.basename(data)} - {os.path.basename(label)}\")\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def normalize(self, tensor, mean, std):\n",
    "        return (tensor - mean) / std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.valid_pairs):\n",
    "            raise IndexError(f\"Index {idx} out of range for valid_pairs.\")\n",
    "        \n",
    "        data_file, label_file = self.valid_pairs[idx]\n",
    "\n",
    "        # Load the data and label\n",
    "        data = nib.load(data_file).get_fdata()\n",
    "        label = nib.load(label_file).get_fdata()\n",
    "\n",
    "        #logger.debug(f\"File: {os.path.basename(data_file)} - Raw data shape: {data.shape}\")\n",
    "        #logger.debug(f\"File: {os.path.basename(label_file)} - Raw label shape: {label.shape}\")\n",
    "\n",
    "        # Convert data and label to tensors\n",
    "        data_tensor = torch.from_numpy(data).float().unsqueeze(0)\n",
    "        label_tensor = torch.from_numpy(label).float().unsqueeze(0)\n",
    "\n",
    "        # Check for invalid values in data and label\n",
    "        check_for_invalid_values(data_tensor, \"data_tensor\")\n",
    "        check_for_invalid_values(label_tensor, \"label_tensor\")\n",
    "\n",
    "        # Normalize tensors\n",
    "        data_tensor = self.normalize(data_tensor, self.mean, self.std)\n",
    "        label_tensor = self.normalize(label_tensor, self.mean, self.std)\n",
    "\n",
    "        # Log stats to check ranges\n",
    "        #logger.debug(f\"Data tensor min: {data_tensor.min()}, max: {data_tensor.max()}, mean: {data_tensor.mean()}\")\n",
    "        #logger.debug(f\"Label tensor min: {label_tensor.min()}, max: {label_tensor.max()}, mean: {label_tensor.mean()}\")\n",
    "\n",
    "        sample = {'data': data_tensor, 'label': label_tensor, 'data_file': data_file, 'label_file': label_file}\n",
    "\n",
    "        # Apply any transforms (e.g., resizing)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "# Transform to resize the data\n",
    "class ResizeTransform:\n",
    "    def __init__(self, target_shape=(256, 256, 128)):\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        data, label = sample['data'], sample['label']\n",
    "        data = F.interpolate(data.unsqueeze(0), size=self.target_shape, mode='trilinear', align_corners=False).squeeze(0)\n",
    "        #label = F.interpolate(label.unsqueeze(0), size=self.target_shape, mode='trilinear', align_corners=False).squeeze(0)\n",
    "        label = F.interpolate(label.unsqueeze(0), size=self.target_shape, mode='nearest').squeeze(0)\n",
    "        #logger.debug(f\"Transform data shape: {data.shape}\")\n",
    "        #logger.debug(f\"Transform label shape: {label.shape}\")\n",
    "        return {'data': data, 'label': label, 'data_file': sample['data_file'], 'label_file': sample['label_file']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf895c23-bfbc-4041-a04b-2f38769399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader creation function\n",
    "def create_dataloader(data_list, label_list, mean, std, transform=None, batch_size=2, shuffle=True, num_workers=8):\n",
    "    dataset = MedicalDataset(data_list, label_list, mean, std, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, drop_last=True, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "# Define directories\n",
    "train_data_dir = '/workspace/RibCage/train-ribfrac-defected-new'  # defected rib\n",
    "train_label_dir = '/workspace/RibCage/train-segmented_ribfrac'  # original rib\n",
    "val_data_dir = '/workspace/RibCage/val-ribfrac-defected-new'\n",
    "val_label_dir = '/workspace/RibCage/val-segmented_ribfrac'\n",
    "\n",
    "# Get list of files\n",
    "train_data_list = sorted(glob.glob(os.path.join(train_data_dir, '*.nii')) + glob.glob(os.path.join(train_data_dir, '*.nii.gz')))\n",
    "train_label_list = sorted(glob.glob(os.path.join(train_label_dir, '*.nii')) + glob.glob(os.path.join(train_label_dir, '*.nii.gz')))\n",
    "val_data_list = sorted(glob.glob(os.path.join(val_data_dir, '*.nii')) + glob.glob(os.path.join(val_data_dir, '*.nii.gz')))\n",
    "val_label_list = sorted(glob.glob(os.path.join(val_label_dir, '*.nii')) + glob.glob(os.path.join(val_label_dir, '*.nii.gz')))\n",
    "\n",
    "# Define the transform\n",
    "resize_transform = ResizeTransform(target_shape=(256, 256, 128))\n",
    "\n",
    "temp_train_dataset = MedicalDataset(train_data_list, train_label_list, mean=0, std=1, transform=resize_transform) \n",
    "train_mean, train_std = compute_mean_std(temp_train_dataset)\n",
    "\n",
    "temp_val_dataset = MedicalDataset(val_data_list, val_label_list, mean=0, std=1, transform=resize_transform) \n",
    "val_mean, val_std = compute_mean_std(temp_val_dataset)\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_loader = create_dataloader(train_data_list, train_label_list,train_mean,train_std, transform=resize_transform, batch_size=2, shuffle=True)\n",
    "val_loader = create_dataloader(val_data_list, val_label_list,val_mean,val_std, transform=resize_transform, batch_size=2, shuffle=False)\n",
    "\n",
    "# Log the number of batches in each loader\n",
    "logger.info(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "logger.info(f\"Number of batches in val_loader: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d32c2-1c6a-4195-a5f2-28ffdf7d4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data and label as NIfTI files\n",
    "def save_nifti(data_tensor, label_tensor, save_dir, batch_idx, is_train=True):\n",
    "    mode = 'train' if is_train else 'val'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert tensors to numpy arrays and detach from GPU (if applicable)\n",
    "    data_np = data_tensor.cpu().numpy().astype(np.float32)  # Convert to NumPy and ensure float32\n",
    "    label_np = label_tensor.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    logger.debug(f\"Original data shape: {data_np.shape}\")\n",
    "    logger.debug(f\"Original label shape: {label_np.shape}\")\n",
    "    \n",
    "    # Remove the singleton dimension (the 1 in the second position)\n",
    "    data_np = data_np.squeeze(1)\n",
    "    label_np = label_np.squeeze(1)\n",
    "\n",
    "    logger.debug(f\"Squeezed data shape: {data_np.shape}\")\n",
    "    logger.debug(f\"Squeezed label shape: {label_np.shape}\")\n",
    "\n",
    "    # Iterate through the batch and save each sample\n",
    "    for i in range(data_np.shape[0]):  # Iterate through the batch\n",
    "        data_filename = os.path.join(save_dir, f'{mode}_data_batch{batch_idx}_instance_{i}.nii.gz')\n",
    "        label_filename = os.path.join(save_dir, f'{mode}_label_batch{batch_idx}_instance_{i}.nii.gz')\n",
    "\n",
    "        nib.save(nib.Nifti1Image(data_np[i], np.eye(4)), data_filename)\n",
    "        nib.save(nib.Nifti1Image(label_np[i], np.eye(4)), label_filename)\n",
    "\n",
    "        print(f\"Saved {data_filename}\")\n",
    "        print(f\"Saved {label_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815174f1-5112-4379-b9db-9dc16fe1b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where you want to save the NIfTI files\n",
    "save_dir_train = '/workspace/RibCage/saved_nifti/train'\n",
    "save_dir_val = '/workspace/RibCage/saved_nifti/val'\n",
    "\n",
    "# Iterate through the DataLoader and save first two batches from training\n",
    "print(\"\\nSaving DataLoader for training data...\")\n",
    "for i, batch in enumerate(train_loader):\n",
    "    data_tensor = batch['data']\n",
    "    label_tensor = batch['label']\n",
    "    \n",
    "    print(f'Batch {i + 1}: Data shape: {data_tensor.shape}, Label shape: {label_tensor.shape}')\n",
    "    save_nifti(data_tensor, label_tensor, save_dir_train, i, is_train=True)\n",
    "    \n",
    "    if i == 1:  # Save only the first two batches\n",
    "        break\n",
    "\n",
    "# Iterate through the DataLoader and save first two batches from validation\n",
    "print(\"\\nSaving DataLoader for validation data...\")\n",
    "for i, batch in enumerate(val_loader):\n",
    "    data_tensor = batch['data']\n",
    "    label_tensor = batch['label']\n",
    "    \n",
    "    print(f'Batch {i + 1}: Data shape: {data_tensor.shape}, Label shape: {label_tensor.shape}')\n",
    "    save_nifti(data_tensor, label_tensor, save_dir_val, i, is_train=False)\n",
    "    \n",
    "    if i == 1:  # Save only the first two batches\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d339ca3-8a77-4b85-92f6-6130f48409e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Model Definition using UNet\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,  \n",
    "    classes=1,\n",
    "    activation=None,\n",
    "    encoder_depth=5,\n",
    "    decoder_channels=(256, 128, 64, 32, 16),\n",
    "    decoder_use_batchnorm=True,\n",
    "    decoder_attention_type=None,\n",
    "    aux_params=None,\n",
    "    strides=((2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2))\n",
    ")\n",
    "\n",
    "# Set up device and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = dice_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Optional: Mixed Precision Training with GradScaler\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1dc8e7c-a31a-4979-be90-3e697b129cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Checkpoints\n",
    "def save_checkpoint(state, filename='checkpoint-defected-encoder.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    logger.info(f\"=> Checkpoint saved to '{filename}'\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename='checkpoint-defected-encoder.pth.tar'):\n",
    "    if os.path.isfile(filename):\n",
    "        logger.info(f\"=> Loading checkpoint '{filename}'\")\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        logger.info(f\"=> Loaded checkpoint '{filename}' (epoch {checkpoint['epoch']})\")\n",
    "        return True\n",
    "    else:\n",
    "        logger.info(f\"=> No checkpoint found at '{filename}'\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f684b759-e9ec-4751-92e9-ecd625703868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_instance_data(data, outputs, labels, epoch, is_train, instance_idx):\n",
    "    mode = 'train' if is_train else 'val'\n",
    "    output_dir = f'/workspace/RibCage/instances/instance_data_epoch_{epoch}/{mode}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert tensors to numpy arrays and cast to float32 (which is supported by NIfTI)\n",
    "    data_np = data.cpu().numpy().astype(np.float32)\n",
    "    outputs_np = outputs.cpu().detach().numpy().astype(np.float32)\n",
    "    labels_np = labels.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    logger.debug(f\"Original data shape: {data_np.shape}\")\n",
    "    logger.debug(f\"Original output shape: {outputs_np.shape}\")\n",
    "    logger.debug(f\"Original labels shape: {labels_np.shape}\")\n",
    "\n",
    "    # Expected shape (D, H, W)\n",
    "    expected_shape = (256, 256, 128)\n",
    "\n",
    "    # If shape has a singleton dimension at index 0, squeeze it out\n",
    "    if data_np.shape[0] == 1:\n",
    "        data_np = data_np.squeeze(0)\n",
    "    if outputs_np.shape[0] == 1:\n",
    "        outputs_np = outputs_np.squeeze(0)\n",
    "    if labels_np.shape[0] == 1:\n",
    "        labels_np = labels_np.squeeze(0)\n",
    "\n",
    "    # Check the shape after squeezing\n",
    "    logger.debug(f\"Squeezed data shape: {data_np.shape}\")\n",
    "    logger.debug(f\"Squeezed output shape: {outputs_np.shape}\")\n",
    "    logger.debug(f\"Squeezed labels shape: {labels_np.shape}\")\n",
    "\n",
    "    # Check the shape before saving (expecting 256x256x128)\n",
    "    if data_np.shape != expected_shape:\n",
    "        raise ValueError(f\"Data shape {data_np.shape} does not match expected shape {expected_shape}\")\n",
    "    if outputs_np.shape != expected_shape:\n",
    "        raise ValueError(f\"Outputs shape {outputs_np.shape} does not match expected shape {expected_shape}\")\n",
    "    if labels_np.shape != expected_shape:\n",
    "        raise ValueError(f\"Labels shape {labels_np.shape} does not match expected shape {expected_shape}\")\n",
    "\n",
    "    # Save input data\n",
    "    nib.save(nib.Nifti1Image(data_np, np.eye(4)), f'{output_dir}/instance_{instance_idx}_input.nii.gz')\n",
    "    \n",
    "    # Save model outputs\n",
    "    nib.save(nib.Nifti1Image(outputs_np, np.eye(4)), f'{output_dir}/instance_{instance_idx}_output.nii.gz')\n",
    "    \n",
    "    # Save ground truth labels\n",
    "    nib.save(nib.Nifti1Image(labels_np, np.eye(4)), f'{output_dir}/instance_{instance_idx}_label.nii.gz')\n",
    "\n",
    "    logger.info(f\"Saved instance data for instance {instance_idx} in epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbb3489-3205-484d-b855-833dea05c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(model, dataloader, criterion, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            inputs = batch['data'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Get encoder output (latent representation)\n",
    "            features = model.encoder(inputs)\n",
    "\n",
    "            logger.debug(f\"Val encoder output shape: {len(features)}\")\n",
    "            \n",
    "            # Save latent representation\n",
    "            #save_latent_representation(features, epoch, batch_idx, is_train=False)\n",
    "            \n",
    "            # Continue with the rest of the forward pass\n",
    "            decoder_output = model.decoder(*features)\n",
    "\n",
    "            logger.debug(f\"Val decoder output shape: {decoder_output.shape}\")\n",
    "            \n",
    "            outputs = model.segmentation_head(decoder_output)\n",
    "\n",
    "            logger.debug(f\"Val output shape: {outputs.shape}\")\n",
    "            \n",
    "            logger.debug(f\"Max Val output value: {torch.max(outputs)}, Min Val output value: {torch.min(outputs)}\")\n",
    "            logger.debug(f\"Max Val label value: {torch.max(labels)}, Min Val label value: {torch.min(labels)}\")\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Save data for each instance in the validation set\n",
    "            for i in range(inputs.size(0)):\n",
    "                save_instance_data(inputs[i], outputs[i], labels[i], epoch, False, batch_idx * dataloader.batch_size + i)\n",
    "\n",
    "    val_loss = running_loss / len(dataloader.dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c22d6c-4a2e-407d-a6eb-077d85c5a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, checkpoint_interval=5, early_stopping_patience=5):\n",
    "    best_loss = float('inf')\n",
    "    no_improvement_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            inputs = batch['data'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logger.debug(f\"Training Epoch {epoch}, Batch {batch_idx} - Input shape: {inputs.shape}, Label shape: {labels.shape}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():  # Mixed precision\n",
    "                # Get encoder output (latent representation)\n",
    "                features = model.encoder(inputs)\n",
    "\n",
    "                logger.debug(f\"Training Epoch {epoch}, Batch {batch_idx} - Train Encoder output shapes: {[f.shape for f in features]}\")\n",
    "                \n",
    "                # Save latent representation\n",
    "                #save_latent_representation(features, epoch, batch_idx, is_train=True)\n",
    "                \n",
    "                # Continue with the rest of the forward pass\n",
    "                decoder_output = model.decoder(*features)\n",
    "                outputs = model.segmentation_head(decoder_output)\n",
    "\n",
    "                logger.debug(f\"Training Epoch {epoch}, Batch {batch_idx} - Train Output shape: {outputs.shape}\")\n",
    "\n",
    "                logger.debug(f\"Max output value: {torch.max(outputs)}, Min output value: {torch.min(outputs)}\")\n",
    "                logger.debug(f\"Max label value: {torch.max(labels)}, Min label value: {torch.min(labels)}\")\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                logger.debug(f\"Loss before scaling: {loss.item()}\")\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Log gradients before and after clipping\n",
    "            #for param in model.parameters():\n",
    "            #    if param.grad is not None:\n",
    "            #        logger.debug(f\"Before clipping - Max gradient: {torch.max(param.grad)}, Min gradient: {torch.min(param.grad)}\")\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            #for param in model.parameters():\n",
    "            #    if param.grad is not None:\n",
    "            #        logger.debug(f\"After clipping - Max gradient: {torch.max(param.grad)}, Min gradient: {torch.min(param.grad)}\")\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Save data for each instance in the training set\n",
    "            #for i in range(inputs.size(0)):\n",
    "            #    save_instance_data(inputs[i], outputs[i], labels[i], epoch, True, batch_idx * train_loader.batch_size + i)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss = val_model(model, val_loader, criterion, epoch)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        logger.info(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save the best model every five intervals\n",
    "        if ((epoch + 1) // checkpoint_interval) % 5 == 0:\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                no_improvement_counter = 0\n",
    "                state = {\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }\n",
    "                save_checkpoint(state, f'/workspace/RibCage/defectedrib-encoder-models/checkpoint_best_interval_{(epoch + 1) // checkpoint_interval}.pth.tar')\n",
    "            else:\n",
    "                no_improvement_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if no_improvement_counter >= early_stopping_patience:\n",
    "            logger.info(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    logger.info('Training and Validation finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82af47-2511-4a67-9d3d-cd1bda547cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Training Started')\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db208c-25e9-404d-89c3-7b08aa6aead0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
